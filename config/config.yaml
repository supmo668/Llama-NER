data:
  dataset_name: "eriktks/conll2003"
  metadata_path: "data/dataset_metadata.yaml"  # Path to dataset metadata
  max_length: 128
  batch_size: 16

model:
  base_model: "unsloth/Llama-3.2-1B-Instruct"
  # "bert-base-uncased" , "meta-llama/Llama-3.2-1B"
  freeze_backbone: true  # or false

training:
  lr: 5e-5
  epochs: 100
  gpus: 1
  log_dir: "lightning_logs"
  checkpoint_dir: "checkpoints"
  use_checkpoint: false
  losses:
    loss_function: "compound_loss"  
    # Options: 'cross_entropy', 'focal_loss', 'label_smoothing', 'compound_loss'
    compound_loss:
      cross_entropy_weight: 0.5
      crf_weight: 0.3
      label_smoothing_weight: 0.2
    focal_loss:
      alpha: 1.0
      gamma: 2.0
    label_smoothing:
      smoothing: 0.1

evaluation:
  load_checkpoint: true  # Whether to load the latest checkpoint for evaluation

advanced:
  use_crf: false
  crf_dropout: 0.1
  peft: lora
